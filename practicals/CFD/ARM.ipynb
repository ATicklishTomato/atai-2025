{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdc08ef9",
   "metadata": {},
   "source": [
    "<div style=\"display:flex; gap:20px;\">\n",
    "  <div style=\"background-color:'#1E1E1E'; padding:10px;\">\n",
    "    <img src=\"output/visuals_Re200.gif\" width=\"600\">\n",
    "  </div>\n",
    "  <div style=\"background-color:'#1E1E1E'; padding:10px;\">\n",
    "    <img src=\"output/visuals_Re400.gif\" width=\"600\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b647eeb6",
   "metadata": {},
   "source": [
    "### Import core libraries\n",
    "We start by importing PyTorch and other essential libraries."
   ]
  },
  {
   "cell_type": "code",
   "id": "6f2eb4ab",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# for cleaner look (set your theme to dark mode)\n",
    "plt.style.use('dark_background')\n",
    "plt.rcParams['figure.facecolor'] = '#1E1E1E'\n",
    "plt.rcParams['axes.facecolor'] = '#1E1E1E'\n",
    "plt.rcParams['savefig.facecolor'] = '#1E1E1E'\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import Image"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "75d2f9cd",
   "metadata": {},
   "source": [
    "################# quickfix for Snellius GPU MIG usage\n",
    "import os \n",
    "import subprocess\n",
    "if \"MIG\" in subprocess.check_output([\"nvidia-smi\", \"-L\"], text=True):\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0423cdd5",
   "metadata": {},
   "source": [
    "### Check CUDA availability\n",
    "Here we check if a GPU is available for faster training. GPU usage is highly recommended."
   ]
  },
  {
   "cell_type": "code",
   "id": "20321fe1",
   "metadata": {},
   "source": [
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device name: {torch.cuda.get_device_name()}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "0b89dcfe",
   "metadata": {},
   "source": [
    "### Data preparation step\n",
    "Fuse the raw data files so they can be read by the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "id": "2a6acf9e",
   "metadata": {},
   "source": [
    "# this box fuses the loose data files such that they can be read by the dataset object\n",
    "base_in = '../../data/CFD/grid/loose/'\n",
    "base_out2 = '../../data/CFD/grid/concat/'\n",
    "os.makedirs(base_out2, exist_ok=True)\n",
    "for Re in [100,150,200,250,300,350,400]:\n",
    "    u = np.load(f\"{base_in}u_grid_Re{Re}.npy\")\n",
    "    v = np.load(f\"{base_in}v_grid_Re{Re}.npy\")\n",
    "    p = np.load(f\"{base_in}p_grid_Re{Re}.npy\")\n",
    "    concat = np.stack([u, v, p], axis=1)\n",
    "    filename_save = f\"{base_out2}uvp_grid_Re{Re}.npy\"\n",
    "    np.save(filename_save, concat)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c09beb26",
   "metadata": {},
   "source": [
    "## Dataset object for standard ARM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00781837",
   "metadata": {},
   "source": [
    "### Model input and output\n",
    "- **Input**: fluid field information (e.g., velocity and pressure at the current timestep, possibly with coordinates/masks).  \n",
    "- **Output**: predicted velocity and pressure fields at the **next timestep**.  \n",
    "This setup makes the model autoregressive: predictions from one step are fed as input to predict the next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d6b3b",
   "metadata": {},
   "source": [
    "### Define Dataset class\n",
    "This class handles how fluid data is loaded and accessed. The dataset consists of 7 different trajectories of flow passing a cilindrical obstacle, each with their own Reynolds number. For the training data we use $Re$=[100,200,300,400] and for validation we use zero-shot validation on $Re$=[150,250,350]. The data consists of the $V_x$, $V_y$ and $p$ fields in 2 spatial dimensions and time. At the top of the notebook two example trajectories can be seen. The dataset object also supplies an obstacle mask, the coordinates and the option to flip-augment the data. Only the boolean obstacle mask will be used."
   ]
  },
  {
   "cell_type": "code",
   "id": "6e7f0ea2",
   "metadata": {},
   "source": [
    "class FlowDataset(Dataset):\n",
    "    def __init__(self, filenames, flip_augmentation=False, timesample=1):\n",
    "        self.sequences = []\n",
    "        self.index_map = []\n",
    "        self.flip_augmentation = flip_augmentation\n",
    "\n",
    "        # coordinates\n",
    "        self.coordsy = np.linspace(-5, 5, 64, endpoint=True)\n",
    "        self.coordsx = np.linspace(-10, 10, 128, endpoint=True)\n",
    "        self.coords = np.array(np.meshgrid(self.coordsx, self.coordsy)).T.reshape(128, 64, 2)\n",
    "        self.coords = torch.tensor(self.coords, dtype=torch.float32).permute(2, 1, 0).cuda()\n",
    "\n",
    "        # use coordinates to make obstacle mask\n",
    "        center = torch.tensor([-5.0, 0.0], device=self.coords.device).view(2, 1, 1)\n",
    "        radius = 0.5\n",
    "        squared_distance = ((self.coords - center) ** 2).sum(dim=0) \n",
    "        self.mask = squared_distance < radius**2  # shape [64, 128]\n",
    "        self.mask = self.mask.unsqueeze(0).cuda()\n",
    "\n",
    "        # sample/read the data\n",
    "        for seq_idx, filename in enumerate(filenames):\n",
    "            data = np.load(filename)  \n",
    "            data = data[::timesample] \n",
    "            self.sequences.append(data)\n",
    "            T = data.shape[0]\n",
    "            self.index_map.extend([(seq_idx, t) for t in range(T - 1)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_idx, t = self.index_map[idx]\n",
    "        seq = self.sequences[seq_idx]\n",
    "        input = seq[t]    \n",
    "        target = seq[t + 1] \n",
    "\n",
    "        # if flip augmentation is true then flip the data horizontally 50% of the time\n",
    "        if self.flip_augmentation and np.random.rand() > 0.5:\n",
    "            input = self.flip(input)\n",
    "            target = self.flip(target)\n",
    "        return (\n",
    "                self.mask, \n",
    "                self.coords, \n",
    "                torch.tensor(input, dtype=torch.float32), \n",
    "                torch.tensor(target, dtype=torch.float32)\n",
    "                )\n",
    "        \n",
    "    def get_trajectory(self, seq_idx):\n",
    "        # returns full trajectory\n",
    "        seq = self.sequences[seq_idx]\n",
    "        return (\n",
    "            self.mask.unsqueeze(0), \n",
    "            self.coords.unsqueeze(0), \n",
    "            torch.tensor(seq, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def flip(self, x):\n",
    "        x = np.flip(x, axis=2).copy()\n",
    "        x[1] *= -1\n",
    "        return x\n",
    "\n",
    "datafolder = '../../data/CFD/grid/concat/'\n",
    "train_files = [\n",
    "    'uvp_grid_Re100.npy',\n",
    "    'uvp_grid_Re200.npy',\n",
    "    'uvp_grid_Re300.npy',\n",
    "    'uvp_grid_Re400.npy'\n",
    "]\n",
    "val_files = [\n",
    "    'uvp_grid_Re150.npy',\n",
    "    'uvp_grid_Re250.npy',\n",
    "    'uvp_grid_Re350.npy'\n",
    "]\n",
    "train_files = [datafolder + f for f in train_files]\n",
    "val_files = [datafolder + f for f in val_files]\n",
    "\n",
    "dt = 20 # only sample every dt timesteps\n",
    "batch_size = 64\n",
    "train_dataset = FlowDataset(train_files, flip_augmentation=False, timesample=dt)\n",
    "val_dataset = FlowDataset(val_files, flip_augmentation=False, timesample=dt)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b38a0468",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d2409",
   "metadata": {},
   "source": [
    "### Define Model architecture\n",
    "Here we build the building blocks of the autoregressive model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ef8408",
   "metadata": {},
   "source": [
    "### U-Net architecture (overview)\n",
    "The model is based on a **U-Net**, which is a type of encoder–decoder neural network with skip connections.\n",
    "- **Encoder**: progressively downsamples the input, extracting features at multiple scales.\n",
    "- **Decoder**: upsamples the features back to the original resolution.\n",
    "- **Skip connections**: link encoder and decoder layers at the same scale, helping the model preserve spatial details.\n",
    "\n",
    "Below is a generic diagram of U-Net (not exactly your model, but the same idea):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "473cdd0a",
   "metadata": {},
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropprob=0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, padding_mode='replicate'),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, padding_mode='replicate'),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout2d(p=dropprob)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SimpleUNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, base_channels=64,mult=[1, 2, 4, 8]):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.enc1 = DoubleConv(in_channels, base_channels * mult[0])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = DoubleConv(base_channels * mult[0], base_channels * mult[1])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = DoubleConv(base_channels * mult[1], base_channels * mult[2])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(base_channels * mult[2], base_channels * mult[3])\n",
    "\n",
    "        # Decoder\n",
    "        self.up3 = nn.ConvTranspose2d(base_channels * mult[3], base_channels * mult[2], kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(2 *base_channels * mult[2], base_channels * mult[2])\n",
    "        self.up2 = nn.ConvTranspose2d(base_channels * mult[2], base_channels * mult[1], kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(2 * base_channels * mult[1], base_channels * mult[1])\n",
    "        self.up1 = nn.ConvTranspose2d(base_channels * mult[1], base_channels * mult[0], kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(2 * base_channels * mult[0], base_channels * mult[0])\n",
    "        \n",
    "        self.out_conv = nn.Conv2d(base_channels * mult[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x1 = self.enc1(x)\n",
    "        x2 = self.enc2(self.pool1(x1))\n",
    "        x3 = self.enc3(self.pool2(x2))\n",
    "\n",
    "        x4 = self.bottleneck(self.pool3(x3))\n",
    "\n",
    "        x = self.up3(x4)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.dec3(x)\n",
    "        x = self.up2(x3)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.dec2(x)\n",
    "        x = self.up1(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.dec1(x)\n",
    "\n",
    "        return self.out_conv(x)\n",
    "    \n",
    "def _amount_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0317ca3",
   "metadata": {},
   "source": [
    "base_channels = 64\n",
    "use_coords = False\n",
    "use_geometry = True\n",
    "in_channels = 3\n",
    "if use_coords:\n",
    "    in_channels += 2 \n",
    "if use_geometry:\n",
    "    in_channels += 1  \n",
    "\n",
    "epochs = 400\n",
    "init_lr = 0.001\n",
    "factor = 0.1\n",
    "patience = 20\n",
    "min_lr = 1e-7\n",
    "\n",
    "train_mode = False # determines whether the model will be trained or loaded from file\n",
    "save_mode = False # if train_mode is True, then saves the model is save_mode is True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleUNet(in_channels=in_channels, out_channels=3, base_channels=base_channels, mult=[1, 2, 2, 2]).to(device)\n",
    "print(f\"Amount of parameters in model: {_amount_params(model)}, will use {in_channels} input channels\")\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=init_lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=factor, patience=patience, min_lr=min_lr)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0d82912c",
   "metadata": {},
   "source": [
    "def _input_fuse(mask, coords, input, use_coords, use_geometry):\n",
    "    # this function fuses the input channels, obstacle mask coordinates and the velocity and pressure data\n",
    "    if use_coords and use_geometry:\n",
    "        input = torch.cat([mask, coords, input], dim=1)\n",
    "    elif use_coords and not use_geometry:\n",
    "        input = torch.cat([coords, input], dim=1)\n",
    "    elif not use_coords and use_geometry:\n",
    "        input = torch.cat([mask, input], dim=1)\n",
    "    return input"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "96d9ddf8",
   "metadata": {},
   "source": [
    "### Training function\n",
    "Define how the model will be trained (loop, loss, optimizer, etc.). Currently we load the model from memory instead of training."
   ]
  },
  {
   "cell_type": "code",
   "id": "a474ff86",
   "metadata": {},
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs):\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        val_loss = []\n",
    "\n",
    "        model.train()\n",
    "        train_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\", leave=False) # for cleaner look during training\n",
    "        for mask, coords, input, target in train_bar:\n",
    "            mask, coords, input, target = mask.to(device), coords.to(device), input.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            input = _input_fuse(mask, coords, input, use_coords, use_geometry) #concat input channels\n",
    "            output = model(input)\n",
    "            train_loss = criterion(output, target)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(train_loss.item())\n",
    "            train_bar.set_postfix(loss=f\"{train_loss.item():.6f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_bar = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for mask, coords, input, target in val_bar:\n",
    "                mask, coords, input, target = mask.to(device), coords.to(device), input.to(device), target.to(device)\n",
    "                input = _input_fuse(mask, coords, input, use_coords, use_geometry)\n",
    "                output = model(input)\n",
    "                loss = criterion(output, target).item()\n",
    "                val_loss.append(loss)\n",
    "                val_bar.set_postfix(loss=f\"{loss:.6f}\")\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1: # plot every 10 epochs and also at the last epoch\n",
    "            tqdm.write(f\"Epoch {epoch+1}/{epochs} - Train Loss: {np.mean(train_losses):.6f}, Val Loss: {np.mean(val_loss):.6f}, LR: {optimizer.param_groups[0]['lr']:.8f}\")\n",
    "        scheduler.step(np.mean(val_loss)) \n",
    "\n",
    "\n",
    "if train_mode == True:\n",
    "    print(\"Training mode enabled, starting training...\")\n",
    "    train(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs)\n",
    "    if save_mode:\n",
    "        save_model(model, '../../models/CFD/model1.pth')\n",
    "else:\n",
    "    print(\"Loading model from file...\")\n",
    "    model.load_state_dict(torch.load('../../models/CFD/model1.pth'))\n",
    "\n",
    "torch.cuda.empty_cache() # clear cache for memory management"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1b83eded",
   "metadata": {},
   "source": [
    "### Rollout method\n",
    "A **rollout** means running the trained model forward in time for many steps, using its predictions as inputs for the next steps.  \n",
    "This is how we evaluate the model’s ability to simulate fluid dynamics beyond a single timestep.\n",
    "\n",
    "The following block also contains helper functions for creating animations and plotting comparisons..."
   ]
  },
  {
   "cell_type": "code",
   "id": "cce06ec6",
   "metadata": {},
   "source": [
    "# helper functions\n",
    "\n",
    "def rollout(model, mask, coords, init_frame, use_coords, use_geometry, length=100):\n",
    "    # this function does a rollout of the ARM\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = _input_fuse(mask, coords, init_frame, use_coords, use_geometry)\n",
    "        output_sequence = []\n",
    "        output_sequence.append(init_frame.squeeze(0).cpu())\n",
    "\n",
    "        for _ in range(length):\n",
    "            output = model(input)\n",
    "            output_sequence.append(output.squeeze(0).cpu())\n",
    "            input = _input_fuse(mask, coords, output, use_coords, use_geometry)\n",
    "\n",
    "    return torch.stack(output_sequence)\n",
    "\n",
    "def magnitude(tensor):\n",
    "    # calculates the radial componentn/magnitude of the 2D velocity field\n",
    "    return torch.sqrt(tensor[:,0,:,:]**2 + tensor[:,1,:,:]**2)\n",
    "\n",
    "def animate_rollout(stacked_pred_vel, stacked_true_vel, stacked_pred_p, stacked_true_p, output_path=\"output/rollout.gif\"):\n",
    "    # this function makes the animation file, given the predicted and true velocity and pressure fields\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    timesteps, x_dim, y_dim = stacked_pred_vel.shape\n",
    "    if timesteps > stacked_true_vel.shape[0]:\n",
    "        timesteps = stacked_true_vel.shape[0]\n",
    "    stacked_pred_vel, stacked_true_vel = stacked_pred_vel.squeeze(1).cpu().numpy(), stacked_true_vel.squeeze(1).cpu().numpy()\n",
    "    stacked_pred_p, stacked_true_p = stacked_pred_p.squeeze(1).cpu().numpy(), stacked_true_p.squeeze(1).cpu().numpy()\n",
    "    vmax_vel = min(np.max(stacked_pred_vel), np.max(stacked_true_vel))\n",
    "    vmax_p = min(np.max(stacked_pred_p), np.max(stacked_true_p))\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 5))\n",
    "    titles = [\"Pred\", \"True\", \"Diff\"]\n",
    "    imgs = []\n",
    "\n",
    "    for i in range(2):\n",
    "        row_imgs = []\n",
    "        for j in range(3):\n",
    "            ax = axes[i, j]\n",
    "            img = ax.imshow(np.zeros((x_dim, y_dim)), cmap='viridis', vmin=0, vmax=vmax_vel if i == 0 else vmax_p)\n",
    "            ax.set_title(titles[j])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_visible(False)\n",
    "            row_imgs.append(img)\n",
    "        imgs.append(row_imgs)\n",
    "\n",
    "    axes[0,0].set_ylabel(r'$\\sqrt{v_x^2 + v_y^2}$')\n",
    "    axes[1,0].set_ylabel(r'$p$')\n",
    "    imgs[0][2].set_cmap('magma')\n",
    "    imgs[1][2].set_cmap('magma')\n",
    "    \n",
    "    def init():\n",
    "        imgs[0][0].set_data(stacked_pred_vel[0])\n",
    "        imgs[0][1].set_data(stacked_true_vel[0])\n",
    "        imgs[1][0].set_data(stacked_pred_p[0])\n",
    "        imgs[1][1].set_data(stacked_true_p[0])\n",
    "        return imgs\n",
    "\n",
    "    def update(frame):\n",
    "\n",
    "        imgs[0][0].set_data(stacked_pred_vel[frame])\n",
    "        imgs[0][1].set_data(stacked_true_vel[frame])\n",
    "        imgs[1][0].set_data(stacked_pred_p[frame])\n",
    "        imgs[1][1].set_data(stacked_true_p[frame])\n",
    "        imgs[0][2].set_data(np.abs(stacked_true_vel[frame] - stacked_pred_vel[frame]))\n",
    "        imgs[1][2].set_data(np.abs(stacked_true_p[frame] - stacked_pred_p[frame]))\n",
    "\n",
    "        fig.suptitle(f\"timestep {frame + 1}\\n\"\n",
    "                     #f\"vmin: {vmin_frame:.4f}, vmax: {vmax_frame:.4f}\")\n",
    "                        #f\"vmax: {vmax_frame:.3f}\"\n",
    "                        )\n",
    "        return imgs\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=timesteps, init_func=init, blit=False, interval=150)\n",
    "    ani.save(output_path, writer=\"ffmpeg\")\n",
    "    plt.close()\n",
    "\n",
    "def _generate_sequence(model, val_dataset, starting_timestep, length, trajectory_select=1):\n",
    "    # this function manages the rollout, magnitude calculation and gets the data ready for plotting functionality or animation functionality\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mask, coords, val_traj = val_dataset.get_trajectory(trajectory_select)\n",
    "        mask, coords, val_traj = mask.to(device), coords.to(device), val_traj.to(device)\n",
    "        val_traj = val_traj[starting_timestep:]\n",
    "\n",
    "        anim_data = rollout(model, mask, coords, val_traj[0].unsqueeze(0), use_coords, use_geometry, length=41) \n",
    "        velocity = magnitude(anim_data).cpu()\n",
    "        velocity_test = magnitude(val_traj).cpu()\n",
    "        pressure = anim_data[:,2,:,:].cpu()\n",
    "        pressure_test = val_traj[:,2,:,:].cpu()\n",
    "    return velocity, velocity_test, pressure, pressure_test\n",
    "\n",
    "def plot_comparison(velocity, velocity_test, pressure, pressure_test):\n",
    "    # this function plots the comparison between predicted and true fields at some timesteps\n",
    "    fig, ax = plt.subplots(4, 4, figsize=(10, 7))\n",
    "    timesteps = [0, 1, 5, 10]\n",
    "    for i, t in enumerate(timesteps):\n",
    "        # turn axis off\n",
    "        for j in range(4):\n",
    "            # only remove axis ticks\n",
    "            ax[i, j].set_xticks([])\n",
    "            ax[i, j].set_yticks([])\n",
    "            for spine in ax[i, j].spines.values():\n",
    "                spine.set_visible(False)\n",
    "        # plot the velocity magnitude and pressure at each time step\n",
    "        ax[i, 0].imshow(velocity[t].numpy(), cmap='viridis')\n",
    "        ax[i, 2].imshow(pressure[t].numpy(), cmap='viridis')\n",
    "        ax[i, 1].imshow(velocity_test[t].numpy(), cmap='viridis')\n",
    "        ax[i, 3].imshow(pressure_test[t].numpy(), cmap='viridis')\n",
    "    ax[0, 0].set_title('Predicted Velocity Magnitude')\n",
    "    ax[0, 2].set_title('Predicted Pressure')\n",
    "    ax[0, 1].set_title('True Velocity Magnitude')\n",
    "    ax[0, 3].set_title('True Pressure')\n",
    "    ax[0, 0].set_ylabel('t={t}'.format(t=timesteps[0]))\n",
    "    ax[1, 0].set_ylabel('t={t}'.format(t=timesteps[1]))\n",
    "    ax[2, 0].set_ylabel('t={t}'.format(t=timesteps[2]))\n",
    "    ax[3, 0].set_ylabel('t={t}'.format(t=timesteps[3]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7381dd5a",
   "metadata": {},
   "source": [
    "### Set starting timestep\n",
    "Choose the timestep where the prediction sequence begins and call the animation function of the model."
   ]
  },
  {
   "cell_type": "code",
   "id": "bca67307",
   "metadata": {},
   "source": [
    "starting_timestep = 6\n",
    "velocity, velocity_true, pressure, pressure_true = _generate_sequence(model, val_dataset, starting_timestep, length=41, trajectory_select=1)\n",
    "animate_rollout(velocity, velocity_true, pressure, pressure_true, output_path=\"output/rollout_model1.gif\")\n",
    "Image(filename=\"output/rollout_model1.gif\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "20265a46",
   "metadata": {},
   "source": [
    "### Plot comparison\n",
    "Here we visualize predicted vs true velocity and pressure fields side-by-side. Although the model predicts the next timestep quite well, the predictions deviate from the true trajectories in the long run..."
   ]
  },
  {
   "cell_type": "code",
   "id": "203fc392",
   "metadata": {},
   "source": [
    "plot_comparison(velocity, velocity_true, pressure, pressure_true)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8a61c329",
   "metadata": {},
   "source": [
    "## Push-forward training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f49fc7",
   "metadata": {},
   "source": [
    "\n",
    "Push-forward training means that during training, the model is rolled out over several timesteps by feeding its **own predictions** back as input.  \n",
    "- At step 1: use ground truth input → predict next step.  \n",
    "- At step 2: feed the prediction from step 1 → predict next step.  \n",
    "- Continue for multiple steps.  \n",
    "\n",
    "This helps the model learn to stay stable during long rollouts, where small errors can otherwise accumulate quickly."
   ]
  },
  {
   "cell_type": "code",
   "id": "279addaa",
   "metadata": {},
   "source": [
    "# since we are now planning on doing the pushforward trick, the\n",
    "# data pipeline needs to be changed such that it supplements multiple timesteps as target from which a single target can be selected\n",
    "\n",
    "class FlowDatasetPushForward(Dataset):\n",
    "    def __init__(self, filenames, flip_augmentation=False, timesample=1, forward_steps=5):\n",
    "        self.sequences = []\n",
    "        self.index_map = []\n",
    "        self.flip_augmentation = flip_augmentation\n",
    "        self.forward_steps = forward_steps # this value determines how many forward timesteps are returned by the dataloader\n",
    "\n",
    "        # coordinates\n",
    "        self.coordsy = np.linspace(-5, 5, 64, endpoint=True) # coords are hardcoded\n",
    "        self.coordsx = np.linspace(-10, 10, 128, endpoint=True)\n",
    "        self.coords = np.array(np.meshgrid(self.coordsx, self.coordsy)).T.reshape(128, 64, 2)\n",
    "        self.coords = torch.tensor(self.coords, dtype=torch.float32).permute(2, 1, 0).cuda()\n",
    "\n",
    "        # obstacle mask \n",
    "        center = torch.tensor([-5.0, 0.0], device=self.coords.device).view(2, 1, 1)  \n",
    "        radius = 0.5\n",
    "        squared_distance = ((self.coords - center) ** 2).sum(dim=0)\n",
    "        self.mask = (squared_distance < radius ** 2).unsqueeze(0).cuda()\n",
    "\n",
    "        # Load/sample data\n",
    "        for seq_idx, filename in enumerate(filenames):\n",
    "            data = np.load(filename)   # [T, C, H, W]\n",
    "            data = data[::timesample]\n",
    "            self.sequences.append(data)\n",
    "            T = data.shape[0]\n",
    "            # ensure enough room for multiple forward solves/rollout steps\n",
    "            self.index_map.extend([(seq_idx, t) for t in range(T - forward_steps)])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq_idx, t = self.index_map[idx]\n",
    "        seq = self.sequences[seq_idx]\n",
    "\n",
    "        input = seq[t]                               # [C, H, W]\n",
    "        targets = seq[t+1:t+self.forward_steps+1]     # [forward_steps, C, H, W]\n",
    "\n",
    "        if self.flip_augmentation and np.random.rand() > 0.5: # flip-augment if wanted\n",
    "            input = self.flip(input)\n",
    "            targets = [self.flip(target) for target in targets]\n",
    "\n",
    "        return (\n",
    "            self.mask, \n",
    "            self.coords, \n",
    "            torch.tensor(input, dtype=torch.float32), \n",
    "            torch.tensor(targets, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def get_trajectory(self, seq_idx):\n",
    "        # returns full trajectory \n",
    "        seq = self.sequences[seq_idx]\n",
    "        return (\n",
    "            self.mask.unsqueeze(0), \n",
    "            self.coords.unsqueeze(0), \n",
    "            torch.tensor(seq, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def flip(self, x):\n",
    "        x = np.flip(x, axis=1).copy()\n",
    "        x[2] *= -1\n",
    "        return x\n",
    "\n",
    "    \n",
    "datafolder = '../../data/CFD/grid/concat/'\n",
    "train_files = [\n",
    "    'uvp_grid_Re100.npy',\n",
    "    'uvp_grid_Re200.npy',\n",
    "    'uvp_grid_Re300.npy',\n",
    "    'uvp_grid_Re400.npy'\n",
    "]\n",
    "val_files = [\n",
    "    'uvp_grid_Re150.npy',\n",
    "    'uvp_grid_Re250.npy',\n",
    "    'uvp_grid_Re350.npy'\n",
    "]\n",
    "train_files = [datafolder + f for f in train_files]\n",
    "val_files = [datafolder + f for f in val_files]\n",
    "\n",
    "dt = 20 # only sample from data every dt timesteps\n",
    "batch_size = 32\n",
    "max_forward_steps = 4 # maximum number of push-forward steps\n",
    "train_dataset = FlowDatasetPushForward(train_files, flip_augmentation=False, timesample=dt, forward_steps=max_forward_steps)\n",
    "val_dataset = FlowDatasetPushForward(val_files, flip_augmentation=False, timesample=dt, forward_steps=max_forward_steps)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model3 = SimpleUNet(in_channels=in_channels, out_channels=3, base_channels=base_channels, mult=[1, 2, 4, 4]).to(device)\n",
    "optimizer3 = Adam(model3.parameters(), lr=init_lr)\n",
    "scheduler3 = ReduceLROnPlateau(optimizer3, mode='min', factor=factor, patience=patience, min_lr=min_lr)\n",
    "criterion = nn.MSELoss()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "790ec5bb",
   "metadata": {},
   "source": [
    "# just to get a feeling for the data\n",
    "\n",
    "for i, (mask, coords, inputs, targets) in enumerate(val_loader):\n",
    "    print(f\"  Mask shape: {mask.shape}\")\n",
    "    print(f\"  Inputs shape: {inputs.shape}\")\n",
    "    print(f\"  Targets shape: {targets.shape}\")\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(inputs[0,0].cpu().numpy(), cmap='viridis')\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[1].imshow(targets[0, max_forward_steps-1,0].cpu().numpy(), cmap='viridis')\n",
    "    ax[1].set_title(f\"{max_forward_steps} timesteps later\")\n",
    "    plt.show()\n",
    "    break"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "48411ae3",
   "metadata": {},
   "source": [
    "Your job is to implement the push-forward training function. Use the _pushforward_schedule() function to sample the amount of forward rollout steps that your model needs to do during each training step. \n",
    "* Think about whether your model should backpropagate loss of all the rollout steps or only a specific portion\n",
    "* Think about a suitable learning strategy that balances rollout-stability and single step accuracy (Your model might forget to accurately predict next-timesteps if only trained on the far-future).\n",
    "* You are allowed to use the obstacle mask, but not the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "id": "8f184516",
   "metadata": {},
   "source": [
    "def _pushforward_schedule(epochs, max_forward_steps=5, method=\"linear\"):\n",
    "    \"\"\"\n",
    "    provide a full pushforward schedule for the given number of epochs, based on the provided method\n",
    "    :param epochs:              The number of epochs\n",
    "    :param max_forward_steps:   The maximum number of forward steps\n",
    "    :param method:              The method to use for scheduling. Options = [linear, exponential, random, cyclic, constant, warmup]\n",
    "    :return:                    numpy array of length epochs with values in range [1, max_forward_steps]\n",
    "    \"\"\"\n",
    "    match method:\n",
    "        case \"linear\":\n",
    "            # Linearly increase number of forward steps across epochs until maximum\n",
    "            steps = np.linspace(1, max_forward_steps, epochs)\n",
    "            return np.rint(steps).astype(np.int32)\n",
    "        case \"exponential\":\n",
    "            # Exponentially increase number of forward steps\n",
    "            steps = np.linspace(0, 1, epochs)\n",
    "            return np.clip((max_forward_steps * (steps**2)).astype(np.int32), 1, max_forward_steps)\n",
    "        case \"random\":\n",
    "            # Uniformly random draw the number of forward steps\n",
    "            return np.random.randint(1, max_forward_steps + 1, size=epochs)\n",
    "        case \"cyclic\":\n",
    "            # Cycle over the possible number of forward steps at a constant rate\n",
    "            cycle = np.concatenate([np.arange(1, max_forward_steps + 1),\n",
    "                                    np.arange(max_forward_steps-1, 0, -1)])\n",
    "            return np.resize(cycle, epochs).astype(np.int32)\n",
    "        case \"constant\":\n",
    "            # Always do max number of steps\n",
    "            return np.full(epochs, max_forward_steps).astype(np.int32)\n",
    "        case \"warmup\":\n",
    "            # Build up to constant with a series of warmup epochs\n",
    "            warmup_epochs = epochs // 3\n",
    "            ramp = np.linspace(1, max_forward_steps, warmup_epochs)\n",
    "            rest = np.full(epochs - warmup_epochs, max_forward_steps)\n",
    "            return np.concatenate([ramp, rest]).astype(np.int32)\n",
    "        case _:\n",
    "            raise NotImplementedError(\"Provided method not implemented\")\n",
    "\n",
    "\n",
    "\n",
    "def train_PF(model, train_loader, val_loader, criterion, optimizer, scheduler, epochs,\n",
    "             max_forward_steps=5, single_step_fraction=0.15, backpropagate_until=1):\n",
    "    pushforward_schedule = _pushforward_schedule(epochs, max_forward_steps=max_forward_steps, method=\"cyclic\")\n",
    "    for epoch in range(epochs):\n",
    "        train_losses = []\n",
    "        val_loss = []\n",
    "        steps = pushforward_schedule[epoch] - 1  # We always do 1 step\n",
    "\n",
    "        model.train()\n",
    "        train_bar = tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\", leave=False) # for cleaner look during training\n",
    "        for mask, coords, input, target in train_bar:\n",
    "            mask, coords, input, target = mask.to(device), coords.to(device), input.to(device), target.to(device)\n",
    "            target = target[:,:steps + 1,:,:,:] # Trim targets we won't use\n",
    "            optimizer.zero_grad()\n",
    "            new_input = _input_fuse(mask, coords, input, use_coords, use_geometry) #concat input channels\n",
    "            output = input + model(new_input)\n",
    "            if np.random.rand() < single_step_fraction:\n",
    "                target = target[:,0,:,:,:]\n",
    "            else:\n",
    "                for step in range(steps):\n",
    "                    new_input = _input_fuse(mask, coords, output.detach(), use_coords, use_geometry)\n",
    "                    output = output + model(new_input)\n",
    "\n",
    "                target = target[:,-1:,:,:,:].squeeze(1)\n",
    "\n",
    "            if target.shape != input.shape and input.shape != output.shape:\n",
    "                raise ValueError(\"Target, input, and output must have same shape\")\n",
    "            train_loss = criterion(output, target)\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            train_losses.append(train_loss.item())\n",
    "            train_bar.set_postfix(loss=f\"{train_loss.item():.6f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_bar = tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{epochs}\", leave=False)\n",
    "        with torch.no_grad():\n",
    "            for mask, coords, input, target in val_bar:\n",
    "                mask, coords, input, target = mask.to(device), coords.to(device), input.to(device), target.to(device)\n",
    "                target = target[:,:steps + 1,:,:,:] # Trim targets we won't use\n",
    "                new_input = _input_fuse(mask, coords, input, use_coords, use_geometry)\n",
    "                output = input + model(new_input)\n",
    "                if np.random.rand() < single_step_fraction:\n",
    "                    target = target[:,0,:,:,:]\n",
    "                else:\n",
    "                    for step in range(steps):\n",
    "                        new_input = _input_fuse(mask, coords, output.detach(), use_coords, use_geometry)\n",
    "                        output = output + model(new_input)\n",
    "\n",
    "                    target = target[:,-1:,:,:,:].squeeze(1)\n",
    "                if target.shape != input.shape and input.shape != output.shape:\n",
    "                    raise ValueError(\"Target, input, and output must have same shape\")\n",
    "                loss = criterion(output, target).item()\n",
    "                val_loss.append(loss)\n",
    "                val_bar.set_postfix(loss=f\"{loss:.6f}\")\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1: # plot every 10 epochs and also at the last epoch\n",
    "            tqdm.write(f\"Epoch {epoch+1}/{epochs} - Train Loss: {np.mean(train_losses):.6f}, Val Loss: {np.mean(val_loss):.6f}, LR: {optimizer.param_groups[0]['lr']:.8f}\")\n",
    "        scheduler.step(np.mean(val_loss))\n",
    "\n",
    "train_mode = True\n",
    "save_mode = False\n",
    "\n",
    "if train_mode == True:\n",
    "    print(\"Training mode enabled, starting training...\")\n",
    "    train_PF(model3, train_loader, val_loader, criterion, optimizer3, scheduler3, epochs, max_forward_steps=max_forward_steps)\n",
    "    print(\"Training loss to beat: 0.002151\")\n",
    "    if save_mode:\n",
    "        save_model(model3, '../../models/CFD/model3.pth')\n",
    "else:\n",
    "    print(\"Loading model from file...\")\n",
    "    model3.load_state_dict(torch.load('../../models/CFD/model3.pth'))\n",
    "\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d540eb3f",
   "metadata": {},
   "source": [
    "Let us now look at the animation and plots from the push-forward trained model. How does the new model compare to the old model?"
   ]
  },
  {
   "cell_type": "code",
   "id": "7dce3649",
   "metadata": {},
   "source": [
    "def _generate_sequence_residual(model, val_dataset, starting_timestep, length, trajectory_select=1):\n",
    "    # this function manages the rollout, magnitude calculation and gets the data ready for plotting functionality or animation functionality\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mask, coords, val_traj = val_dataset.get_trajectory(trajectory_select)\n",
    "        mask, coords, val_traj = mask.to(device), coords.to(device), val_traj.to(device)\n",
    "        val_traj = val_traj[starting_timestep:]\n",
    "\n",
    "        anim_data = rollout_residual(model, mask, coords, val_traj[0].unsqueeze(0), use_coords, use_geometry, length=41)\n",
    "        velocity = magnitude(anim_data).cpu()\n",
    "        velocity_test = magnitude(val_traj).cpu()\n",
    "        pressure = anim_data[:,2,:,:].cpu()\n",
    "        pressure_test = val_traj[:,2,:,:].cpu()\n",
    "    return velocity, velocity_test, pressure, pressure_test\n",
    "\n",
    "def rollout_residual(model, mask, coords, init_frame, use_coords, use_geometry, length=100):\n",
    "    # this function does a rollout of the ARM\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        input = init_frame\n",
    "        input_fused = _input_fuse(mask, coords, init_frame, use_coords, use_geometry)\n",
    "        output_sequence = []\n",
    "        output_sequence.append(init_frame.squeeze(0).cpu())\n",
    "\n",
    "        for _ in range(length):\n",
    "            output = model(input_fused) + input\n",
    "            output_sequence.append(output.squeeze(0).cpu())\n",
    "            input = output\n",
    "            input_fused = _input_fuse(mask, coords, output, use_coords, use_geometry)\n",
    "\n",
    "    return torch.stack(output_sequence)\n",
    "\n",
    "velocity, velocity_true, pressure, pressure_true = _generate_sequence_residual(model3, val_dataset, starting_timestep, length=41, trajectory_select=1)\n",
    "animate_rollout(velocity, velocity_true, pressure, pressure_true, output_path=\"output/rollout_model3.gif\")\n",
    "Image(filename=\"output/rollout_model3.gif\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b2e9ad29",
   "metadata": {},
   "source": [
    "plot_comparison(velocity, velocity_true, pressure, pressure_true)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grad311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
